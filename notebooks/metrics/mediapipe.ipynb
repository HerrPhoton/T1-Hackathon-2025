{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "014c3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "from src.config.path import SEGMENTATION_MP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "042e380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_annotations(label_path, image_shape):\n",
    "\n",
    "    h, w = image_shape[:2]\n",
    "    polygons = []\n",
    "\n",
    "    label_path = Path(label_path)\n",
    "    if not label_path.exists():\n",
    "        return []\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 5:\n",
    "                coords = np.array(list(map(float, parts[1:])), dtype=np.float32)\n",
    "                coords = coords.reshape(-1, 2)\n",
    "\n",
    "                coords[:, 0] *= w\n",
    "                coords[:, 1] *= h\n",
    "\n",
    "                polygons.append(coords)\n",
    "                \n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bca312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_mask(polygons, shape):\n",
    "    mask = np.zeros(shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    for polygon in polygons:\n",
    "        cv2.fillPoly(mask, [np.int32(polygon)], 1)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67411951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(mask_pred, mask_gt):\n",
    "    intersection = np.logical_and(mask_pred, mask_gt)\n",
    "    union = np.logical_or(mask_pred, mask_gt)\n",
    "    \n",
    "    return intersection.sum() / (union.sum() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "571b201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(iou_values, n_bootstrap=1000, ci=0.95):\n",
    "    bootstrapped_means = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = resample(iou_values)\n",
    "        bootstrapped_means.append(np.mean(sample))\n",
    "    \n",
    "    lower = np.percentile(bootstrapped_means, (1 - ci) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + ci) / 2 * 100)\n",
    "    \n",
    "    return np.mean(iou_values), (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba0571ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path=SEGMENTATION_MP_PATH)\n",
    "options = vision.ImageSegmenterOptions(base_options=base_options, output_category_mask=True)\n",
    "model = vision.ImageSegmenter.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "148d339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../datasets/merged/test\"\n",
    "\n",
    "images_dir = Path(dataset_path) / \"images\"\n",
    "labels_dir = Path(dataset_path) / \"labels\"\n",
    "\n",
    "images = list(images_dir.glob(\"*.jpg\")) + list(images_dir.glob(\"*.png\"))\n",
    "labels = list(labels_dir.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3ad574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [04:28<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU [CI95]: 0.9685 [0.9673, 0.9697]\n"
     ]
    }
   ],
   "source": [
    "iou_values = []\n",
    "\n",
    "for image_path, label_path in tqdm(zip(images, labels), total=len(images)):\n",
    "\n",
    "    image_path = str(image_path)\n",
    "    label_path = str(label_path)\n",
    "\n",
    "    image = mp.Image.create_from_file(image_path)\n",
    "\n",
    "    segmentation_result = model.segment(image)\n",
    "    category_mask = segmentation_result.category_mask\n",
    "\n",
    "    image_data = image.numpy_view()\n",
    "    shape = image_data.shape\n",
    "    \n",
    "    gt_polygons = load_yolo_annotations(label_path, shape)\n",
    "\n",
    "    mask_gt = polygons_to_mask(gt_polygons, shape)\n",
    "    mask_pred = segmentation_result.category_mask.numpy_view()\n",
    "    mask_pred = (mask_pred == 0).astype(np.uint8)\n",
    "    \n",
    "    iou = compute_iou(mask_pred, mask_gt)\n",
    "    iou_values.append(iou)\n",
    "\n",
    "mean_iou, (low, high) = bootstrap_ci(iou_values)\n",
    "\n",
    "print(f\"IoU [CI95]: {mean_iou:.4f} [{low:.4f}, {high:.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
