{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014c3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import resample\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "from src.config.path import SEGMENTATION_MP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042e380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_annotations(label_path, image_shape):\n",
    "\n",
    "    h, w = image_shape[:2]\n",
    "    polygons = []\n",
    "\n",
    "    label_path = Path(label_path)\n",
    "    if not label_path.exists():\n",
    "        return []\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) > 5:\n",
    "                coords = np.array(list(map(float, parts[1:])), dtype=np.float32)\n",
    "                coords = coords.reshape(-1, 2)\n",
    "\n",
    "                coords[:, 0] *= w\n",
    "                coords[:, 1] *= h\n",
    "\n",
    "                polygons.append(coords)\n",
    "                \n",
    "    return polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bca312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_mask(polygons, shape):\n",
    "    mask = np.zeros(shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    for polygon in polygons:\n",
    "        cv2.fillPoly(mask, [np.int32(polygon)], 1)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67411951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(mask_pred, mask_gt):\n",
    "    intersection = np.logical_and(mask_pred, mask_gt)\n",
    "    union = np.logical_or(mask_pred, mask_gt)\n",
    "    \n",
    "    return intersection.sum() / (union.sum() + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571b201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(values, n_bootstrap=1000, ci=0.95):\n",
    "    bootstrapped_means = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = resample(values)\n",
    "        bootstrapped_means.append(np.mean(sample))\n",
    "    \n",
    "    lower = np.percentile(bootstrapped_means, (1 - ci) / 2 * 100)\n",
    "    upper = np.percentile(bootstrapped_means, (1 + ci) / 2 * 100)\n",
    "    \n",
    "    return np.mean(values), (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0571ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\My_Files\\Projects\\nn\\T1-Hackathon-2025\\.venv\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\image_segmenter.py:158: UserWarning: MessageFactory class is deprecated. Please use GetMessageClass() instead of MessageFactory.GetPrototype. MessageFactory class will be removed after 2024.\n",
      "  graph_config = self._runner.get_graph_config()\n"
     ]
    }
   ],
   "source": [
    "base_options = python.BaseOptions(model_asset_path=SEGMENTATION_MP_PATH)\n",
    "options = vision.ImageSegmenterOptions(base_options=base_options, output_category_mask=True)\n",
    "model = vision.ImageSegmenter.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "148d339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../../datasets/merged/test\"\n",
    "\n",
    "images_dir = Path(dataset_path) / \"images\"\n",
    "labels_dir = Path(dataset_path) / \"labels\"\n",
    "\n",
    "images = list(images_dir.glob(\"*.jpg\")) + list(images_dir.glob(\"*.png\"))\n",
    "labels = list(labels_dir.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3ad574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4165/4165 [15:48<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU [95% CI]: 0.9746 [0.9729, 0.9761]\n"
     ]
    }
   ],
   "source": [
    "values = []\n",
    "\n",
    "for image_path, label_path in tqdm(zip(images, labels), total=len(images)):\n",
    "\n",
    "    image_path = str(image_path)\n",
    "    label_path = str(label_path)\n",
    "\n",
    "    image = mp.Image.create_from_file(image_path)\n",
    "\n",
    "    segmentation_result = model.segment(image)\n",
    "    category_mask = segmentation_result.category_mask\n",
    "\n",
    "    image_data = image.numpy_view()\n",
    "    shape = image_data.shape\n",
    "    \n",
    "    gt_polygons = load_yolo_annotations(label_path, shape)\n",
    "\n",
    "    mask_gt = polygons_to_mask(gt_polygons, shape)\n",
    "\n",
    "    mask_pred = segmentation_result.category_mask.numpy_view()\n",
    "    mask_pred = (mask_pred != 0).astype(np.uint8)\n",
    "    \n",
    "    iou = compute_iou(mask_pred, mask_gt)\n",
    "    values.append(iou)\n",
    "\n",
    "mean_iou, (low_iou, high_iou) = bootstrap_ci(values)\n",
    "\n",
    "print(f\"IoU [95% CI]: {mean_iou:.4f} [{low_iou:.4f}, {high_iou:.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
